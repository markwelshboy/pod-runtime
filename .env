#!/usr/bin/env bash
# ======================================================================
# ComfyUI Vast-AI Environment Configuration
# ======================================================================

# ----- Project Paths -----
# Discover repo root as the directory containing this .env file
SCRIPT_PATH="${BASH_SOURCE[0]}"
if [[ -L "$SCRIPT_PATH" ]]; then
  SCRIPT_PATH="$(readlink -f "$SCRIPT_PATH")"
fi
REPO_ROOT="$(cd "$(dirname "$SCRIPT_PATH")" && pwd)"
export REPO_ROOT

# ----- Core -----
export DEBIAN_FRONTEND=noninteractive
export PATH="/opt/venv/bin:$PATH"
export PY="/opt/venv/bin/python"
export PIP="/opt/venv/bin/pip"

# ----- Project Paths -----
export COMFY_HOME="/workspace/ComfyUI"
export COMFY=$COMFY_HOME
export COMFYUI_PATH=$COMFY_HOME
export COMFY_LOGS="/workspace/logs"
export CUSTOM_DIR="$COMFY_HOME/custom_nodes"
export CUSTOM_LOG_DIR="${COMFY_LOGS}/custom_nodes"
export CACHE_DIR="$COMFY_HOME/cache"
export OUTPUT_DIR="$COMFY_HOME/output"
export BUNDLES_DIR="$COMFY_HOME/bundles"
export WORKFLOW_DIR="$COMFY_HOME/user/default/workflows"

# ================================================================
# Torch install + version/channel management
# ================================================================
export TORCH_CUDA="${TORCH_CUDA:-cu128}"
export TORCH_STABLE_VER="${TORCH_STABLE_VER:-2.9.1}"
# Leave TORCH_CHANNEL/TORCH_NIGHTLY_VER unset for auto; set explicitly if you want to override:
# export TORCH_CHANNEL=stable
# export TORCH_NIGHTLY_VER=2.10.0.dev20251111
export SAGE_ALLOW_COMPAT_REUSE="${SAGE_ALLOW_COMPAT_REUSE:-0}"

# ----- Python / pip -----
export PIP_NO_INPUT=1
export PIP_DISABLE_PIP_VERSION_CHECK=1
export NUMPY_VER="${NUMPY_VER:-numpy>=2.2,<2.3}"
export CUPY_VER="${CUPY_VER:-cupy-cuda12x>=13.6.0}"
export OPENCV_VER="${OPENCV_VER:-opencv-contrib-python==4.12.0.88}"
cat > /workspace/pins.txt <<EOF
${NUMPY_VER}
${CUPY_VER}
${OPENCV_VER}
EOF
export PIP_BUILD_CONSTRAINT=/workspace/pins.txt

# ----- Custom-nodes HF / bundle controls -----

export CUSTOM_NODES_PIP_CACHE_DIR="${CUSTOM_NODES_PIP_CACHE_DIR:-${CACHE_DIR}/pip-cache}"
export PIP_CACHE_DIR="${PIP_CACHE_DIR:-${CACHE_DIR}/pip-cache}"

# ----- Hugging Face (mirror storage) -----
export HF_LOCAL_REPO="${HF_LOCAL_REPO:-${CACHE_DIR}/.hf_repo}"

export HF_REPO_ID="markwelshboyx/hearmemanAI-comfyUI-workflows"
export HF_REPO_TYPE="${HF_REPO_TYPE:-dataset}" # or model
export CN_BRANCH="${CN_BRANCH:-main}"
export HF_TOKEN="${HF_TOKEN:-}"   # set manually or inject from Vast
export HF_API_BASE="https://huggingface.co"
# Auth mode (default = auto)
export HF_AUTH_MODE=auto   # probe â†’ only send token on 401/403
# export HF_AUTH_MODE=always # always send token for huggingface.co
# export HF_AUTH_MODE=never  # never send token
# HF-specific concurrency (fallbacks to global SPLIT/MCONN/CHUNK)
export HF_SPLIT=8
export HF_MCONN=4
export HF_CHUNK=4M
# Probe tuning (defaults are fine)
# export HF_PROBE_TIMEOUT=5
# export HF_PROBE_REDIRECTS=5
# export HF_PROBE_RETRY=0

# ----- Git repo URL for ComfyUI / Hearmeman24 -----
export COMFY_REPO_URL="https://github.com/comfyanonymous/ComfyUI"
export HEARMEMAN_REPO="https://github.com/Hearmeman24/comfyui-wan.git"

export GIT_AUTHOR_NAME="RunPod Mirror Robot"
export GIT_COMMITTER_NAME="RunPod Mirror Robot"
export GIT_AUTHOR_EMAIL="runpod-mirror-bot@users.noreply.huggingface.co"
export GIT_COMMITTER_EMAIL="runpod-mirror-bot@users.noreply.huggingface.co"

# Logical set name; controls which family of bundles we fetch/publish
export CUSTOM_NODES_BUNDLE_TAG="${CUSTOM_NODES_BUNDLE_TAG:-Wan2_1__Wan2_2__CUDA_12_8}"
export PUSH_CUSTOM_NODES_BUNDLE="${PUSH_CUSTOM_NODES_BUNDLE:-0}"  # 1=push after install, 0=skip push
export CUSTOM_NODES_FORCE_INSTALL="${CUSTOM_NODES_FORCE_INSTALL:-0}"  # 1=force install, 0=skip force, try bundle first, then build

# ----- PIP cache for custom-node requirements -----

# If non-empty, we try to cache pip wheels for custom-node dependencies only.
# Cache key is: py<ABI>_<pins_signature> (e.g. py312_np2d2d6_cupy13d6d0_cv4d12d0)
export USE_PIP_CACHE_FOR_CUSTOM_NODES="${USE_PIP_CACHE_FOR_CUSTOM_NODES:-0}"

# If 1, after a successful custom-node install we snapshot the pip cache
# and push it to HF as: pip_cache/pip_cache_py<ABI>_<pins>.tgz
export PUSH_CUSTOM_NODES_PIP_CACHE="${PUSH_CUSTOM_NODES_PIP_CACHE:-0}"  # 1=push after install, 0=skip push

# ----- GPU Detection (robust) -----
#GPU_NAME="$(nvidia-smi --query-gpu=name --format=csv,noheader | head -n1 | tr '[:space:]' '_' )"
export GPU_NAME=LOCAL_TEST
#export GPU_COUNT="$(nvidia-smi -L | wc -l)"
export GPU_COUNT=0

# 1) Strong explicit matches by marketing name (underscore-normalized)
case "$GPU_NAME" in
  # Blackwell
  *RTX_5090*|*GeForce_RTX_5090*|*GB200*|*B100*|*B200*)
    GPU_ARCH="sm_120"
    TORCH_INDEX="https://download.pytorch.org/whl/nightly/cu128"
    ;;
  # Ada (desktop/workstation/server)
  *RTX_4090*|*RTX_6000_ADA*|*L40S*|*L4*)
    GPU_ARCH="sm_89"
    TORCH_INDEX="https://download.pytorch.org/whl/nightly/cu128"
    ;;
  # Hopper / Ampere DC
  *H100*|*H800*)
    GPU_ARCH="sm_90"
    TORCH_INDEX="https://download.pytorch.org/whl/nightly/cu128"
    ;;
  *A100*|*A800*)
    GPU_ARCH="sm_80"
    TORCH_INDEX="https://download.pytorch.org/whl/nightly/cu128"
    ;;
  # Ampere Wks/desktop
  *3090*|*A40*|*A5000*)
    GPU_ARCH="sm_86"
    TORCH_INDEX="https://download.pytorch.org/whl/nightly/cu121"
    ;;
  # Fallback; will refine below
  *)
    GPU_ARCH="sm_89"
    TORCH_INDEX="https://download.pytorch.org/whl/nightly/cu128"
    ;;
esac

# 2) Hardware-accurate override using nvidia-smi (works before Torch exists)
#    compute_cap prints e.g. "12.0"; convert to "sm_120"
if command -v nvidia-smi >/dev/null 2>&1; then
  CC="$(nvidia-smi --query-gpu=compute_cap --format=csv,noheader 2>/dev/null | head -n1 | tr -d '.' )"
  if [ -n "$CC" ]; then
    GPU_ARCH="sm_${CC}"
  fi
fi

export GPU_ARCH TORCH_INDEX

# (optional) Known-good Sage commit stays the same for now
export SAGE_COMMIT="68de379"

export PUSH_SAGE_BUNDLE="${PUSH_SAGE_BUNDLE:-0}"      # 1=push after build, 0=skip push
export SAGE_FORCE_REBUILD="${SAGE_FORCE_REBUILD:-0}"  # 1=force build even if one exists on HF, 0=skip force, follow HF 

# ----- Ports -----
export PORT_MAIN=8188
export PORT_GPU0=8288
export PORT_GPU1=8388
export PORT_JUPYTER=8888

# ----- Misc -----
export TMUX_TMPDIR="/tmp/tmux"
export BASH_ENV="$REPO_ROOT/helpers.sh"    # auto-load helper functions
export COMFY_ENV_TAG="$(date +%Y%m%d_%H%M)_${GPU_NAME}_${GPU_COUNT}GPU"
export LOGFILE_BOOTSTRAP="/workspace/bootstrap_run.log"

export MAX_NODE_JOBS="${MAX_NODE_JOBS:-16}"         # parallelism cap
export GIT_DEPTH="${GIT_DEPTH:-1}"                 # 0 means full; 1 is shallow

# ======================================================================
# Custom Nodes to Install by Default - No other method set (build/list)
# ======================================================================

# -- Default/fallback nodes (must be exported before helpers that resolve lists)
export DEFAULT_NODES=(
  https://github.com/ssitu/ComfyUI_UltimateSDUpscale.git
  https://github.com/obisin/ComfyUI-FSampler.git
  https://github.com/cmeka/ComfyUI-WanMoEScheduler.git
  https://github.com/lrzjason/ComfyUI-VAE-Utils.git
  https://github.com/ltdrdata/ComfyUI-Impact-Pack.git
  https://github.com/chflame163/ComfyUI_LayerStyle.git
  https://github.com/chflame163/ComfyUI_LayerStyle_Advance.git
  https://github.com/kijai/ComfyUI-KJNodes.git
  https://github.com/rgthree/rgthree-comfy.git
  https://github.com/JPS-GER/ComfyUI_JPS-Nodes.git
  https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes.git
  https://github.com/Jordach/comfy-plasma.git
  https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite.git
  https://github.com/bash-j/mikey_nodes.git
  https://github.com/Fannovel16/comfyui_controlnet_aux.git
  https://github.com/yolain/ComfyUI-Easy-Use.git
  https://github.com/kijai/ComfyUI-Florence2.git
  https://github.com/ShmuelRonen/ComfyUI-LatentSyncWrapper.git
  https://github.com/WASasquatch/was-node-suite-comfyui.git
  https://github.com/theUpsider/ComfyUI-Logic.git
  https://github.com/cubiq/ComfyUI_essentials.git
  https://github.com/chrisgoringe/cg-image-picker.git
  https://github.com/chrisgoringe/cg-use-everywhere.git
  https://github.com/kijai/ComfyUI-segment-anything-2.git
  https://github.com/ClownsharkBatwing/RES4LYF
  https://github.com/welltop-cn/ComfyUI-TeaCache.git
  https://github.com/Fannovel16/ComfyUI-Frame-Interpolation.git
  https://github.com/Jonseed/ComfyUI-Detail-Daemon.git
  https://github.com/kijai/ComfyUI-WanVideoWrapper.git
  https://github.com/BadCafeCode/masquerade-nodes-comfyui.git
  https://github.com/1038lab/ComfyUI-RMBG.git
  https://github.com/M1kep/ComfyLiterals.git
  https://github.com/wildminder/ComfyUI-VibeVoice.git
  https://github.com/kijai/ComfyUI-WanAnimatePreprocess.git
  https://github.com/ltdrdata/ComfyUI-Manager
)

# --- Where to pull the manifest ---
export CUSTOM_NODES_MANIFEST_URL="https://raw.githubusercontent.com/markwelshboy/pod-runtime/main/default_custom_nodes.manifest"
#export CUSTOM_NODES_MANIFEST_URL="https://raw.githubusercontent.com/markwelshboy/pod-runtime/refs/heads/main/default_custom_nodes.manifest"

# Repos that must be cloned with --recursive. Match by substring.
# Example: "ComfyUI_UltimateSDUpscale AnotherRepoName"
export CUSTOM_NODES_RECURSIVE_REPOS="ComfyUI_UltimateSDUpscale"

# Requirements rewrites for custom-node consolidated requirements.
# Format: CUSTOM_NODES_REQ_REWRITE_N="pkg_name|replacement"
# - pkg_name:      just the bare package name as it appears at line start in requirements
# - replacement:   new requirement line, or "#" to just drop it entirely
#
# This fixes the bare 'matplotlib' that is breaking on py3.12:
#export CUSTOM_NODES_REQ_REWRITE_1="matplotlib|matplotlib>=3.8.0"
# librosa fix
#export CUSTOM_NODES_REQ_REWRITE_2="librosa==0.6.2  librosa>=0.10.0"
# Example drops a known-bad package line completely:
# export CUSTOM_NODES_REQ_REWRITE_3="oldbadpkg|#"

# ======================================================================
# ComfyUI ARIA2-Based Downloader Environment Variables
# ======================================================================

# --- Where to pull the manifest ---
export MODEL_MANIFEST_URL="https://raw.githubusercontent.com/markwelshboy/pod-runtime/main/model_manifest.json"

# --- Aria2 RPC ---
export ARIA2_HOST=127.0.0.1
export ARIA2_PORT=6969
export ARIA2_SECRET=KissMeQuick       # optional, recommended

# --- Performance knobs ---
export ARIA2_MAX_CONC=8
export ARIA2_SPLIT=16
export ARIA2_MCONN=8
export ARIA2_CHUNK=1M
export ARIA2_FALLOC=none

# --- Aria2 Progress/Checking ---
export ARIA2_PROGRESS_INTERVAL=60     # seconds between snapshots
export ARIA2_PROGRESS_BAR_WIDTH=40
export ARIA2_NAME_COL_WIDTH=56        # width of name column
export ARIA2_PROGRESS_CLEAR=0         # 0 append to log, 1 clear on TTY only
export ARIA2_PROBE=1                  # 1=enable 0=disable light probe
export ARIA2_PROBE_RETRIES=0
export ARIA2_PROBE_DELAY=1
export ARIA2_PROBE_TIMEOUT=10
export ARIA2_SHUTDOWN_ON_INT=1        # 1=stop aria2 on SIGINT, 0=ignore

# Define model paths
export CHECKPOINTS_DIR="$COMFY_HOME/models/checkpoints"
export DIFFUSION_MODELS_DIR="$COMFY_HOME/models/diffusion_models"
export TEXT_ENCODERS_DIR="$COMFY_HOME/models/text_encoders"
export CLIP_VISION_DIR="$COMFY_HOME/models/clip_vision"
export VAE_DIR="$COMFY_HOME/models/vae"
export LORAS_DIR="$COMFY_HOME/models/loras"
export DETECTION_DIR="$COMFY_HOME/models/detection"
export CTRL_DIR="$COMFY_HOME/models/controlnet/SDXL/controlnet-union-sdxl-1.0"
export UPSCALE_DIR="$COMFY_HOME/models/upscale_models"

# --- Section toggles set in Vast.ai Web UI (enable/override any of these) ---
#export download_native_480p=false
#export download_native_720p=false
#export download_wan22=false
#export download_wan22_lightning=true
#export download_vace=false
#export download_wan_animate=false
#export download_clip=true
#export download_vae=true
#export download_detection=false
#export download_optimization_loras=false
#export download_wan_fun_and_sdxl_helper=false

# --- CivitAi Specific ---
export CIVITAI_TOKEN="${CIVITAI_TOKEN:-}"                                             # set manually or inject from Vast
export CHECKPOINT_IDS_TO_DOWNLOAD="${CHECKPOINT_IDS_TO_DOWNLOAD:-replace_with_ids}"   
export LORAS_IDS_TO_DOWNLOAD="${LORAS_IDS_TO_DOWNLOAD:-replace_with_ids}"             
export CIVITAI_LOG_DIR="${COMFY_LOGS:-/workspace/logs/civitai}"
export CIVITAI_DEBUG="${CIVITAI_DEBUG:-0}"                                            # 1=enable debug output 

# ======================================================================
# AI Training Vast-AI Environment Configuration
# ======================================================================

export WANDB_TOKEN="${WANDB_TOKEN:-}"                                 # set manually or inject from Vast
export AI_TOOLKIT_AUTH="${AI_TOOLKIT_AUTH:-super_secret_password}"    # set manually or inject from Vast

export TRAINING_RUNMODE="${TRAINING_RUNMODE:-DIFFUSION-PIPE}"

export TRAINING_LOGS="/workspace/training_logs"

export TRAINING_REPO_URL="${TRAINING_REPO_URL:-https://github.com/markwelshboy/ai-training-wan22.git}"
export TRAINING_REPO_DIR="${TRAINING_REPO_DIR:-/workspace/ai-training-wan22}"

export TRAINING_SRC_DIR="${TRAINING_REPO_DIR}/src"

export VENV_DIR="${VENV_DIR:-/opt/venv}"
export CONDA_DIR="${CONDA_DIR:-/opt/conda}"
export CONDA_ENV_NAME="${CONDA_ENV_NAME:-diffusion-pipe}"

# --- Where to pull the training model manifest ---
export TRAINING_MODEL_MANIFEST_URL="{TRAINING_MODEL_MANIFEST_URL:-https://raw.githubusercontent.com/markwelshboy/pod-runtime/main/training_model_manifest.json"

# ======================================================================
